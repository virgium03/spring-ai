spring.application.name=spring-ai

# Web
spring.web.resources.static-locations=classpath:/META-INF/resources/webjars/,classpath:/static/

# Maximum time static resources should be cached
spring.web.resources.cache.cachecontrol.max-age=12h

spring.servlet.multipart.max-file-size=100MB
spring.servlet.multipart.max-request-size=100MB

server.servlet.context-path=/ai

# Thymeleaf
spring.thymeleaf.mode=HTML

spring.thymeleaf.encoding=UTF-8

spring.thymeleaf.cache=false

spring.resources.cache.period=0

# Internationalization
spring.messages.basename=messages/messages

spring.jackson.serialization.indent_output=true

# Spring AI
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3.2

# Whether to pull models at startup-time and how
spring.ai.ollama.init.pull-model-strategy=when_missing

# Include this type of models in the initialization task
spring.ai.ollama.init.embedding.include=true

# Additional models to initialize besides the ones configured via default properties
spring.ai.ollama.init.embedding.additional-models=nomic-embed-text

# The name of the supported model to use. You can use dedicated Embedding Model types
spring.ai.ollama.embedding.options.model=nomic-embed-text

# Sets the size of the context window used to generate the next token
spring.ai.ollama.embedding.options.num-ctx=8192

# Logging
logging.level.org.springframework.ai.chat.client.advisor=DEBUG


